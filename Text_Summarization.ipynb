{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Text Summarization.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_7bbdnU2eWFt",
        "outputId": "9747e9c8-4cbe-43dd-81fc-ccf9aad2e6c0"
      },
      "source": [
        "pip install SpeechRecognition"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: SpeechRecognition in /usr/local/lib/python3.7/dist-packages (3.8.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XQFI1SfgoVgF",
        "outputId": "ee1afeb4-eae1-433e-a2e9-8f50e51ff8d4"
      },
      "source": [
        "pip install gensim"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (3.6.0)\n",
            "Requirement already satisfied: scipy>=0.18.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.4.1)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim) (5.2.1)\n",
            "Requirement already satisfied: six>=1.5.0 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.15.0)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from gensim) (1.21.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Ay3cVVD0pcAv",
        "outputId": "b06a5c08-6f59-4c3e-e233-0640fe86e431"
      },
      "source": [
        "pip install pyLDAvis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyLDAvis in /usr/local/lib/python3.7/dist-packages (3.3.1)\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.4.1)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.11.3)\n",
            "Requirement already satisfied: gensim in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (3.6.0)\n",
            "Requirement already satisfied: joblib in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.0.1)\n",
            "Requirement already satisfied: funcy in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.16)\n",
            "Requirement already satisfied: future in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.16.0)\n",
            "Requirement already satisfied: numpy>=1.20.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.21.2)\n",
            "Requirement already satisfied: numexpr in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (2.7.3)\n",
            "Requirement already satisfied: pandas>=1.2.0 in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (1.3.3)\n",
            "Requirement already satisfied: scikit-learn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.22.2.post1)\n",
            "Requirement already satisfied: sklearn in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (0.0)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.7/dist-packages (from pyLDAvis) (57.4.0)\n",
            "Requirement already satisfied: pytz>=2017.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2018.9)\n",
            "Requirement already satisfied: python-dateutil>=2.7.3 in /usr/local/lib/python3.7/dist-packages (from pandas>=1.2.0->pyLDAvis) (2.8.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.7.3->pandas>=1.2.0->pyLDAvis) (1.15.0)\n",
            "Requirement already satisfied: smart-open>=1.2.1 in /usr/local/lib/python3.7/dist-packages (from gensim->pyLDAvis) (5.2.1)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from jinja2->pyLDAvis) (2.0.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9cb3i5N0e0gz",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "64780392-6006-4034-cbba-2c1292ab5a78"
      },
      "source": [
        "import speech_recognition as sr\n",
        "# from pydub import AudioSegment\n",
        "# from pydub.silence import split_on_silence\n",
        "import nltk\n",
        "nltk.download('stopwords')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[nltk_data] Downloading package stopwords to /root/nltk_data...\n",
            "[nltk_data]   Unzipping corpora/stopwords.zip.\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {},
          "execution_count": 4
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "GgIbEjLpn6ZK",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0c9e1644-589f-4657-cadb-8a997c8950a4"
      },
      "source": [
        "import re\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "from pprint import pprint\n",
        "\n",
        "#gensim \n",
        "import gensim\n",
        "import gensim.corpora as corpora\n",
        "from gensim.utils import simple_preprocess\n",
        "from gensim.models import CoherenceModel\n",
        "\n",
        "#Spacy for lemmatization\n",
        "import spacy\n",
        "\n",
        "# Plotting\n",
        "import pyLDAvis\n",
        "import pyLDAvis.gensim_models\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/past/types/oldstr.py:5: DeprecationWarning: Using or importing the ABCs from 'collections' instead of from 'collections.abc' is deprecated since Python 3.3,and in 3.9 it will stop working\n",
            "  from collections import Iterable\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/decomposition/_lda.py:29: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  EPS = np.finfo(np.float).eps\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "B01VreYRHio8",
        "outputId": "d9b945a8-cbfd-4658-99e5-2b558e46a7c9"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "exm-kIDroHzv",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 91
        },
        "outputId": "454b04d5-b63b-4a35-95f1-750e4d620d7e"
      },
      "source": [
        "from google.colab import files\n",
        "\n",
        "uploaded = files.upload()\n",
        "\n",
        "for fn in uploaded.keys():\n",
        "  print('User uploaded file \"{name}\" with length {length} bytes'.format(\n",
        "      name=fn, length=len(uploaded[fn])))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-4e521619-9457-4ede-8802-5dc805bffece\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-4e521619-9457-4ede-8802-5dc805bffece\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {}
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Saving text_dummy.txt to text_dummy.txt\n",
            "User uploaded file \"text_dummy.txt\" with length 1560 bytes\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sUOXlJ3ono8w",
        "outputId": "eefe4147-3a49-4037-bcdf-1377f278561e"
      },
      "source": [
        "r = sr.Recognizer()\n",
        "\n",
        "with sr.AudioFile('/content/drive/MyDrive/Speech Recognition/LongWelcome.wav') as source:\n",
        "  audio = r.record(source)\n",
        "  r.adjust_for_ambient_noise(source)\n",
        "  try:\n",
        "      text = r.recognize_google(audio, language=\"en-US\")\n",
        "      print(text)\n",
        "  except LookupError:\n",
        "      print(\"Sorry your voice is ugly\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thank you for choosing the Olympus dictation management system the Olympus dictation management system gives you the power to manage your dictations transcriptions and document seamlessly and to improve the productivity of your daily work for example you can automatically send the dictation files are transcribed documents do your assistant off the old Side by email or FTP if you're using the speech recognition software the speech recognition engine works in the background to support your document creation we hope you enjoy the simple flexible reliable and Secure Solutions from Olympus thank you for choosing the Olympus dictation management system the Olympus dictation management system gives you the power to manage your dictations transcriptions and document seamlessly and to improve the productivity for example you can automatically send transcribed in the background to support you and we hope you enjoy the simple flexible reliable and Secure Solutions from Olympus thank you for choosing the Olympus dictation management system the Olympus dictation management system gives you the power to manage your dictations transcriptions and document seamlessly and to improve the productivity and we hope you enjoy the simple flexible reliable and Secure Solutions from Olympus thank you for choosing the Olympus dictation management system the Olympus dictation management system gives you the power to manage your dictations transcriptions and document seamlessly and to improve the productivity of flexible reliable and Secure Solutions from Olympus\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "1Z_BMuCGrbc_"
      },
      "source": [
        "from nltk.corpus import stopwords\n",
        "stop_words = stopwords.words('english')\n",
        "stop_words.extend(['from', 'subject', 're', 'edu', 'use'])"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dHLo6KtBso1b"
      },
      "source": [
        "list_word = [(text.strip())]"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Aw4u7_o5r0ld",
        "outputId": "2a124c7d-adf8-413c-80c6-ef5fb6e410d0"
      },
      "source": [
        "def sent_to_words(sentences):\n",
        "    for sentence in sentences:\n",
        "        yield(gensim.utils.simple_preprocess(str(sentence), deacc=True))  # deacc=True removes punctuations\n",
        "\n",
        "data_words = list(sent_to_words(list_word))\n",
        "\n",
        "print(data_words)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['thank', 'you', 'for', 'choosing', 'the', 'olympus', 'dictation', 'management', 'system', 'the', 'olympus', 'dictation', 'management', 'system', 'gives', 'you', 'the', 'power', 'to', 'manage', 'your', 'dictations', 'transcriptions', 'and', 'document', 'seamlessly', 'and', 'to', 'improve', 'the', 'productivity', 'of', 'your', 'daily', 'work', 'for', 'example', 'you', 'can', 'automatically', 'send', 'the', 'dictation', 'files', 'are', 'transcribed', 'documents', 'do', 'your', 'assistant', 'off', 'the', 'old', 'side', 'by', 'email', 'or', 'ftp', 'if', 'you', 're', 'using', 'the', 'speech', 'recognition', 'software', 'the', 'speech', 'recognition', 'engine', 'works', 'in', 'the', 'background', 'to', 'support', 'your', 'document', 'creation', 'we', 'hope', 'you', 'enjoy', 'the', 'simple', 'flexible', 'reliable', 'and', 'secure', 'solutions', 'from', 'olympus', 'thank', 'you', 'for', 'choosing', 'the', 'olympus', 'dictation', 'management', 'system', 'the', 'olympus', 'dictation', 'management', 'system', 'gives', 'you', 'the', 'power', 'to', 'manage', 'your', 'dictations', 'transcriptions', 'and', 'document', 'seamlessly', 'and', 'to', 'improve', 'the', 'productivity', 'for', 'example', 'you', 'can', 'automatically', 'send', 'transcribed', 'in', 'the', 'background', 'to', 'support', 'you', 'and', 'we', 'hope', 'you', 'enjoy', 'the', 'simple', 'flexible', 'reliable', 'and', 'secure', 'solutions', 'from', 'olympus', 'thank', 'you', 'for', 'choosing', 'the', 'olympus', 'dictation', 'management', 'system', 'the', 'olympus', 'dictation', 'management', 'system', 'gives', 'you', 'the', 'power', 'to', 'manage', 'your', 'dictations', 'transcriptions', 'and', 'document', 'seamlessly', 'and', 'to', 'improve', 'the', 'productivity', 'and', 'we', 'hope', 'you', 'enjoy', 'the', 'simple', 'flexible', 'reliable', 'and', 'secure', 'solutions', 'from', 'olympus', 'thank', 'you', 'for', 'choosing', 'the', 'olympus', 'dictation', 'management', 'system', 'the', 'olympus', 'dictation', 'management', 'system', 'gives', 'you', 'the', 'power', 'to', 'manage', 'your', 'dictations', 'transcriptions', 'and', 'document', 'seamlessly', 'and', 'to', 'improve', 'the', 'productivity', 'of', 'flexible', 'reliable', 'and', 'secure', 'solutions', 'from', 'olympus']]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "E4f98lfcPb1d",
        "outputId": "89174e7a-bd1a-42b8-f663-11b171629588"
      },
      "source": [
        "print(len(text))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "1560\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Fi_cREmbluLk",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "09bbb31e-af44-401f-9686-b0058ea7c37e"
      },
      "source": [
        "# Build the bigram and trigram models (Bigram adalah 2 kata sedangkan Trigram adalah 3 kata)\n",
        "bigram = gensim.models.Phrases(data_words, min_count=5, threshold=100) # higher threshold fewer phrases.\n",
        "trigram = gensim.models.Phrases(bigram[data_words], threshold=100)  \n",
        "\n",
        "# Faster way to get a sentence clubbed as a trigram/bigram\n",
        "bigram_mod = gensim.models.phrases.Phraser(bigram)\n",
        "trigram_mod = gensim.models.phrases.Phraser(trigram)\n",
        "\n",
        "# See trigram example\n",
        "print(trigram_mod[bigram_mod[data_words[0]]])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['thank', 'you', 'for', 'choosing', 'the', 'olympus', 'dictation', 'management', 'system', 'the', 'olympus', 'dictation', 'management', 'system', 'gives', 'you', 'the', 'power', 'to', 'manage', 'your', 'dictations', 'transcriptions', 'and', 'document', 'seamlessly', 'and', 'to', 'improve', 'the', 'productivity', 'of', 'your', 'daily', 'work', 'for', 'example', 'you', 'can', 'automatically', 'send', 'the', 'dictation', 'files', 'are', 'transcribed', 'documents', 'do', 'your', 'assistant', 'off', 'the', 'old', 'side', 'by', 'email', 'or', 'ftp', 'if', 'you', 're', 'using', 'the', 'speech', 'recognition', 'software', 'the', 'speech', 'recognition', 'engine', 'works', 'in', 'the', 'background', 'to', 'support', 'your', 'document', 'creation', 'we', 'hope', 'you', 'enjoy', 'the', 'simple', 'flexible', 'reliable', 'and', 'secure', 'solutions', 'from', 'olympus', 'thank', 'you', 'for', 'choosing', 'the', 'olympus', 'dictation', 'management', 'system', 'the', 'olympus', 'dictation', 'management', 'system', 'gives', 'you', 'the', 'power', 'to', 'manage', 'your', 'dictations', 'transcriptions', 'and', 'document', 'seamlessly', 'and', 'to', 'improve', 'the', 'productivity', 'for', 'example', 'you', 'can', 'automatically', 'send', 'transcribed', 'in', 'the', 'background', 'to', 'support', 'you', 'and', 'we', 'hope', 'you', 'enjoy', 'the', 'simple', 'flexible', 'reliable', 'and', 'secure', 'solutions', 'from', 'olympus', 'thank', 'you', 'for', 'choosing', 'the', 'olympus', 'dictation', 'management', 'system', 'the', 'olympus', 'dictation', 'management', 'system', 'gives', 'you', 'the', 'power', 'to', 'manage', 'your', 'dictations', 'transcriptions', 'and', 'document', 'seamlessly', 'and', 'to', 'improve', 'the', 'productivity', 'and', 'we', 'hope', 'you', 'enjoy', 'the', 'simple', 'flexible', 'reliable', 'and', 'secure', 'solutions', 'from', 'olympus', 'thank', 'you', 'for', 'choosing', 'the', 'olympus', 'dictation', 'management', 'system', 'the', 'olympus', 'dictation', 'management', 'system', 'gives', 'you', 'the', 'power', 'to', 'manage', 'your', 'dictations', 'transcriptions', 'and', 'document', 'seamlessly', 'and', 'to', 'improve', 'the', 'productivity', 'of', 'flexible', 'reliable', 'and', 'secure', 'solutions', 'from', 'olympus']\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/phrases.py:598: UserWarning: For a faster implementation, use the gensim.models.phrases.Phraser class\n",
            "  warnings.warn(\"For a faster implementation, use the gensim.models.phrases.Phraser class\")\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XgLiiu_gJVyt"
      },
      "source": [
        "# Define functions for stopwords, bigrams, trigrams and lemmatization\n",
        "def remove_stopwords(texts):\n",
        "    return [[word for word in simple_preprocess(str(doc)) if word not in stop_words] for doc in texts]\n",
        "\n",
        "def make_bigrams(texts):\n",
        "    return [bigram_mod[doc] for doc in texts]\n",
        "\n",
        "def make_trigrams(texts):\n",
        "    return [trigram_mod[bigram_mod[doc]] for doc in texts]\n",
        "\n",
        "def lemmatization(texts, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV']):\n",
        "    \"\"\"https://spacy.io/api/annotation\"\"\"\n",
        "    texts_out = []\n",
        "    for sent in texts:\n",
        "        doc = nlp(\" \".join(sent)) \n",
        "        texts_out.append([token.lemma_ for token in doc if token.pos_ in allowed_postags])\n",
        "    return texts_out"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xPonUKxlJnK1",
        "outputId": "57c15032-95de-4ebb-8fd7-65279cba496a"
      },
      "source": [
        "# Remove Stop Words\n",
        "data_words_nostops = remove_stopwords(data_words)\n",
        "\n",
        "# Form Bigrams\n",
        "data_words_bigrams = make_bigrams(data_words_nostops)\n",
        "\n",
        "# Initialize spacy 'en' model, keeping only tagger component (for efficiency)\n",
        "# python3 -m spacy download en\n",
        "nlp = spacy.load('en', disable=['parser', 'ner'])\n",
        "\n",
        "# Do lemmatization keeping only noun, adj, vb, adv\n",
        "data_lemmatized = lemmatization(data_words_bigrams, allowed_postags=['NOUN', 'ADJ', 'VERB', 'ADV'])\n",
        "\n",
        "print(data_lemmatized[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n",
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n",
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:126: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n",
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[['thank', 'choose', 'dictation', 'management', 'system', 'olympus', 'dictation', 'management', 'system', 'give', 'power', 'manage', 'dictation', 'transcription', 'document', 'seamlessly', 'improve', 'productivity', 'daily', 'work', 'example', 'automatically', 'send', 'dictation', 'file', 'transcribe', 'document', 'assistant', 'old', 'side', 'email', 'use', 'speech', 'recognition', 'software', 'speech', 'recognition', 'engine', 'work', 'background', 'support', 'document', 'creation', 'hope', 'enjoy', 'simple', 'flexible', 'reliable', 'secure', 'solution', 'thank', 'choose', 'dictation', 'management', 'system', 'olympus', 'dictation', 'management', 'system', 'give', 'power', 'manage', 'dictation', 'transcription', 'document', 'seamlessly', 'improve', 'productivity', 'example', 'automatically', 'send', 'transcribe', 'background', 'support', 'hope', 'enjoy', 'simple', 'flexible', 'reliable', 'secure', 'solution', 'thank', 'choose', 'dictation', 'management', 'system', 'olympus', 'dictation', 'management', 'system', 'give', 'power', 'manage', 'dictation', 'transcription', 'document', 'seamlessly', 'improve', 'productivity', 'hope', 'enjoy', 'simple', 'flexible', 'reliable', 'secure', 'solution', 'thank', 'choose', 'dictation', 'management', 'system', 'olympus', 'dictation', 'management', 'system', 'give', 'power', 'manage', 'dictation', 'transcription', 'document', 'seamlessly', 'improve', 'productivity', 'flexible', 'reliable', 'secure', 'solution', 'olympus']]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n",
            "/usr/local/lib/python3.7/dist-packages/catalogue.py:138: DeprecationWarning: SelectableGroups dict interface is deprecated. Use select.\n",
            "  for entry_point in AVAILABLE_ENTRY_POINTS.get(self.entry_point_namespace, []):\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "o31Hi_lsJpdP",
        "outputId": "a50dff85-417a-4a6b-e029-e34ae91a87ba"
      },
      "source": [
        "# Create Dictionary\n",
        "id2word = corpora.Dictionary(data_lemmatized)\n",
        "\n",
        "# Create Corpus\n",
        "texts = data_lemmatized\n",
        "\n",
        "# Term Document Frequency\n",
        "corpus = [id2word.doc2bow(text) for text in texts]\n",
        "\n",
        "# View\n",
        "print(corpus[:1])"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[(0, 1), (1, 2), (2, 2), (3, 4), (4, 1), (5, 1), (6, 13), (7, 6), (8, 1), (9, 1), (10, 3), (11, 2), (12, 1), (13, 4), (14, 4), (15, 3), (16, 4), (17, 4), (18, 8), (19, 1), (20, 5), (21, 4), (22, 4), (23, 2), (24, 4), (25, 4), (26, 4), (27, 2), (28, 1), (29, 3), (30, 1), (31, 4), (32, 2), (33, 2), (34, 8), (35, 4), (36, 2), (37, 4), (38, 1), (39, 2)]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "W4HWUwsZJ20d",
        "outputId": "83313d51-5521-4773-bbeb-2b53f7dd0215"
      },
      "source": [
        "[[(id2word[id], freq) for id, freq in cp] for cp in corpus[:1]]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[[('assistant', 1),\n",
              "  ('automatically', 2),\n",
              "  ('background', 2),\n",
              "  ('choose', 4),\n",
              "  ('creation', 1),\n",
              "  ('daily', 1),\n",
              "  ('dictation', 13),\n",
              "  ('document', 6),\n",
              "  ('email', 1),\n",
              "  ('engine', 1),\n",
              "  ('enjoy', 3),\n",
              "  ('example', 2),\n",
              "  ('file', 1),\n",
              "  ('flexible', 4),\n",
              "  ('give', 4),\n",
              "  ('hope', 3),\n",
              "  ('improve', 4),\n",
              "  ('manage', 4),\n",
              "  ('management', 8),\n",
              "  ('old', 1),\n",
              "  ('olympus', 5),\n",
              "  ('power', 4),\n",
              "  ('productivity', 4),\n",
              "  ('recognition', 2),\n",
              "  ('reliable', 4),\n",
              "  ('seamlessly', 4),\n",
              "  ('secure', 4),\n",
              "  ('send', 2),\n",
              "  ('side', 1),\n",
              "  ('simple', 3),\n",
              "  ('software', 1),\n",
              "  ('solution', 4),\n",
              "  ('speech', 2),\n",
              "  ('support', 2),\n",
              "  ('system', 8),\n",
              "  ('thank', 4),\n",
              "  ('transcribe', 2),\n",
              "  ('transcription', 4),\n",
              "  ('use', 1),\n",
              "  ('work', 2)]]"
            ]
          },
          "metadata": {},
          "execution_count": 18
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZJQppHvAL_JF",
        "outputId": "73d7e22b-c667-4b45-e779-a1a716959f5e"
      },
      "source": [
        "# Build LDA model\n",
        "lda_model = gensim.models.ldamodel.LdaModel(corpus=corpus,\n",
        "                                           id2word=id2word,\n",
        "                                           num_topics=10, \n",
        "                                           random_state=100,\n",
        "                                           update_every=1,\n",
        "                                           chunksize=100,\n",
        "                                           passes=10,\n",
        "                                           alpha='auto',\n",
        "                                           per_word_topics=True)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n",
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vGNN6_6sMBSu",
        "outputId": "fb0f106d-33cf-483a-e841-328bda251f21"
      },
      "source": [
        "# Print the Keyword in the 10 topics\n",
        "pprint(lda_model.print_topics())\n",
        "doc_lda = lda_model[corpus]"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(0,\n",
            "  '0.035*\"dictation\" + 0.030*\"system\" + 0.029*\"document\" + 0.028*\"management\" '\n",
            "  '+ 0.027*\"give\" + 0.027*\"olympus\" + 0.027*\"flexible\" + 0.026*\"choose\" + '\n",
            "  '0.026*\"solution\" + 0.026*\"manage\"'),\n",
            " (1,\n",
            "  '0.027*\"dictation\" + 0.026*\"management\" + 0.026*\"document\" + 0.025*\"system\" '\n",
            "  '+ 0.025*\"seamlessly\" + 0.025*\"olympus\" + 0.025*\"solution\" + 0.025*\"enjoy\" + '\n",
            "  '0.025*\"power\" + 0.025*\"reliable\"'),\n",
            " (2,\n",
            "  '0.025*\"dictation\" + 0.025*\"document\" + 0.025*\"system\" + 0.025*\"management\" '\n",
            "  '+ 0.025*\"productivity\" + 0.025*\"send\" + 0.025*\"automatically\" + '\n",
            "  '0.025*\"olympus\" + 0.025*\"power\" + 0.025*\"seamlessly\"'),\n",
            " (3,\n",
            "  '0.098*\"dictation\" + 0.061*\"management\" + 0.061*\"system\" + 0.046*\"document\" '\n",
            "  '+ 0.038*\"olympus\" + 0.031*\"productivity\" + 0.031*\"secure\" + 0.031*\"power\" + '\n",
            "  '0.031*\"thank\" + 0.031*\"reliable\"'),\n",
            " (4,\n",
            "  '0.025*\"dictation\" + 0.025*\"document\" + 0.025*\"system\" + 0.025*\"management\" '\n",
            "  '+ 0.025*\"power\" + 0.025*\"recognition\" + 0.025*\"automatically\" + '\n",
            "  '0.025*\"olympus\" + 0.025*\"speech\" + 0.025*\"secure\"'),\n",
            " (5,\n",
            "  '0.025*\"dictation\" + 0.025*\"document\" + 0.025*\"system\" + 0.025*\"secure\" + '\n",
            "  '0.025*\"recognition\" + 0.025*\"olympus\" + 0.025*\"power\" + '\n",
            "  '0.025*\"productivity\" + 0.025*\"management\" + 0.025*\"reliable\"'),\n",
            " (6,\n",
            "  '0.026*\"dictation\" + 0.026*\"management\" + 0.025*\"system\" + 0.025*\"give\" + '\n",
            "  '0.025*\"document\" + 0.025*\"solution\" + 0.025*\"thank\" + 0.025*\"productivity\" '\n",
            "  '+ 0.025*\"seamlessly\" + 0.025*\"transcription\"'),\n",
            " (7,\n",
            "  '0.027*\"dictation\" + 0.026*\"management\" + 0.026*\"system\" + 0.026*\"improve\" + '\n",
            "  '0.025*\"secure\" + 0.025*\"document\" + 0.025*\"seamlessly\" + 0.025*\"flexible\" + '\n",
            "  '0.025*\"solution\" + 0.025*\"power\"'),\n",
            " (8,\n",
            "  '0.025*\"dictation\" + 0.025*\"system\" + 0.025*\"document\" + 0.025*\"management\" '\n",
            "  '+ 0.025*\"secure\" + 0.025*\"seamlessly\" + 0.025*\"reliable\" + 0.025*\"solution\" '\n",
            "  '+ 0.025*\"simple\" + 0.025*\"improve\"'),\n",
            " (9,\n",
            "  '0.025*\"dictation\" + 0.025*\"document\" + 0.025*\"system\" + 0.025*\"manage\" + '\n",
            "  '0.025*\"olympus\" + 0.025*\"seamlessly\" + 0.025*\"management\" + 0.025*\"choose\" '\n",
            "  '+ 0.025*\"flexible\" + 0.025*\"secure\"')]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "DDkY852HMuLT",
        "outputId": "a8681293-c424-438f-c6b4-e6c2b5d41738"
      },
      "source": [
        "# Compute Perplexity\n",
        "print('\\nPerplexity: ', lda_model.log_perplexity(corpus))  # a measure of how good the model is. lower the better.\n",
        "\n",
        "# Compute Coherence Score\n",
        "coherence_model_lda = CoherenceModel(model=lda_model, texts=data_lemmatized, dictionary=id2word, coherence='c_v')\n",
        "coherence_lda = coherence_model_lda.get_coherence()\n",
        "print('\\nCoherence Score: ', coherence_lda)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/gensim/models/ldamodel.py:1077: DeprecationWarning: Calling np.sum(generator) is deprecated, and in the future will give a different result. Use np.sum(np.fromiter(generator)) or the python sum builtin instead.\n",
            "  score += np.sum(cnt * logsumexp(Elogthetad + Elogbeta[:, int(id)]) for id, cnt in doc)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "Perplexity:  -4.13007171556007\n",
            "\n",
            "Coherence Score:  0.6519963090522832\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "nZxsb_RWOIgP",
        "outputId": "be07350c-fa4a-48fc-dcdc-c115e226df5d"
      },
      "source": [
        "# Visualize the topics\n",
        "pyLDAvis.enable_notebook()\n",
        "vis = pyLDAvis.gensim_models.prepare(lda_model, corpus, id2word, mds='mmds')\n",
        "vis"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/pyLDAvis/_prepare.py:247: FutureWarning: In a future version of pandas all arguments of DataFrame.drop except for the argument 'labels' will be keyword-only\n",
            "  by='saliency', ascending=False).head(R).drop('saliency', 1)\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n",
            "/usr/local/lib/python3.7/dist-packages/sklearn/metrics/pairwise.py:56: DeprecationWarning: `np.float` is a deprecated alias for the builtin `float`. To silence this warning, use `float` by itself. Doing this will not modify any behavior and is safe. If you specifically wanted the numpy scalar type, use `np.float64` here.\n",
            "Deprecated in NumPy 1.20; for more details and guidance: https://numpy.org/devdocs/release/1.20.0-notes.html#deprecations\n",
            "  dtype = np.float\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "\n",
              "<link rel=\"stylesheet\" type=\"text/css\" href=\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v1.0.0.css\">\n",
              "\n",
              "\n",
              "<div id=\"ldavis_el1741399267795566886538442035\"></div>\n",
              "<script type=\"text/javascript\">\n",
              "\n",
              "var ldavis_el1741399267795566886538442035_data = {\"mdsDat\": {\"x\": [0.019772339010036305, -0.0013358032368797103, -0.002207966662979389, -0.0022400677826099297, -0.0022394925956040336, -0.0023294247568232027, -0.002345270526246148, -0.00236018024042661, -0.002364106254680819, -0.0023500269537864616], \"y\": [0.03862524232515017, -0.0027542128438321416, -0.004292210239622951, -0.004345381498569702, -0.004372137028457772, -0.00454631245826461, -0.004547596604861541, -0.0045881279446625045, -0.004585949603755872, -0.004593314103123069], \"topics\": [1, 2, 3, 4, 5, 6, 7, 8, 9, 10], \"cluster\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [99.77765244606759, 0.030796898654612933, 0.026452461868408734, 0.026443297071502274, 0.026440872722241215, 0.026396829892268065, 0.026387033542192757, 0.01981006794564476, 0.01981006358006986, 0.01981002865547066]}, \"tinfo\": {\"Term\": [\"dictation\", \"system\", \"management\", \"document\", \"olympus\", \"secure\", \"productivity\", \"power\", \"thank\", \"seamlessly\", \"reliable\", \"transcription\", \"improve\", \"manage\", \"choose\", \"solution\", \"flexible\", \"give\", \"simple\", \"enjoy\", \"hope\", \"support\", \"recognition\", \"work\", \"example\", \"speech\", \"background\", \"transcribe\", \"automatically\", \"send\", \"dictation\", \"management\", \"system\", \"document\", \"olympus\", \"productivity\", \"secure\", \"power\", \"thank\", \"reliable\", \"seamlessly\", \"transcription\", \"manage\", \"choose\", \"improve\", \"solution\", \"flexible\", \"give\", \"simple\", \"enjoy\", \"hope\", \"support\", \"recognition\", \"work\", \"example\", \"speech\", \"background\", \"transcribe\", \"automatically\", \"send\", \"file\", \"engine\", \"creation\", \"software\", \"old\", \"email\", \"side\", \"daily\", \"assistant\", \"use\", \"send\", \"automatically\", \"transcribe\", \"background\", \"work\", \"speech\", \"example\", \"recognition\", \"support\", \"hope\", \"enjoy\", \"simple\", \"give\", \"flexible\", \"choose\", \"solution\", \"manage\", \"transcription\", \"improve\", \"reliable\", \"document\", \"dictation\", \"system\", \"olympus\", \"management\", \"thank\", \"seamlessly\", \"power\", \"productivity\", \"secure\", \"assistant\", \"creation\", \"software\", \"engine\", \"use\", \"email\", \"file\", \"daily\", \"old\", \"side\", \"automatically\", \"example\", \"speech\", \"send\", \"support\", \"transcribe\", \"recognition\", \"background\", \"work\", \"hope\", \"enjoy\", \"simple\", \"improve\", \"flexible\", \"secure\", \"seamlessly\", \"solution\", \"give\", \"choose\", \"power\", \"dictation\", \"management\", \"system\", \"transcription\", \"document\", \"productivity\", \"manage\", \"reliable\", \"olympus\", \"thank\", \"software\", \"assistant\", \"file\", \"engine\", \"creation\", \"old\", \"email\", \"use\", \"side\", \"daily\", \"send\", \"speech\", \"example\", \"automatically\", \"background\", \"work\", \"support\", \"transcribe\", \"recognition\", \"enjoy\", \"simple\", \"hope\", \"seamlessly\", \"solution\", \"improve\", \"power\", \"flexible\", \"reliable\", \"manage\", \"transcription\", \"thank\", \"dictation\", \"document\", \"management\", \"system\", \"olympus\", \"productivity\", \"give\", \"choose\", \"secure\", \"engine\", \"email\", \"software\", \"assistant\", \"creation\", \"file\", \"use\", \"old\", \"side\", \"daily\", \"automatically\", \"speech\", \"example\", \"send\", \"support\", \"recognition\", \"work\", \"background\", \"transcribe\", \"simple\", \"hope\", \"enjoy\", \"give\", \"solution\", \"thank\", \"transcription\", \"seamlessly\", \"manage\", \"productivity\", \"secure\", \"dictation\", \"management\", \"system\", \"document\", \"choose\", \"olympus\", \"power\", \"reliable\", \"improve\", \"flexible\", \"file\", \"creation\", \"engine\", \"software\", \"email\", \"assistant\", \"old\", \"side\", \"use\", \"daily\", \"send\", \"automatically\", \"recognition\", \"example\", \"speech\", \"transcribe\", \"background\", \"work\", \"support\", \"simple\", \"enjoy\", \"hope\", \"give\", \"solution\", \"improve\", \"seamlessly\", \"secure\", \"flexible\", \"reliable\", \"manage\", \"productivity\", \"power\", \"document\", \"dictation\", \"system\", \"management\", \"olympus\", \"choose\", \"transcription\", \"thank\", \"engine\", \"creation\", \"file\", \"software\", \"email\", \"old\", \"assistant\", \"side\", \"daily\", \"use\", \"send\", \"automatically\", \"example\", \"transcribe\", \"speech\", \"recognition\", \"background\", \"work\", \"support\", \"simple\", \"hope\", \"enjoy\", \"give\", \"flexible\", \"manage\", \"seamlessly\", \"choose\", \"improve\", \"solution\", \"secure\", \"power\", \"dictation\", \"document\", \"system\", \"olympus\", \"management\", \"productivity\", \"reliable\", \"thank\", \"transcription\", \"file\", \"engine\", \"software\", \"creation\", \"email\", \"old\", \"assistant\", \"side\", \"daily\", \"use\", \"send\", \"automatically\", \"transcribe\", \"background\", \"speech\", \"example\", \"work\", \"recognition\", \"support\", \"hope\", \"enjoy\", \"simple\", \"give\", \"flexible\", \"solution\", \"improve\", \"choose\", \"manage\", \"transcription\", \"seamlessly\", \"dictation\", \"document\", \"management\", \"system\", \"olympus\", \"power\", \"productivity\", \"reliable\", \"secure\", \"thank\", \"file\", \"engine\", \"software\", \"creation\", \"email\", \"old\", \"assistant\", \"side\", \"daily\", \"use\", \"send\", \"automatically\", \"transcribe\", \"background\", \"speech\", \"example\", \"work\", \"recognition\", \"support\", \"hope\", \"enjoy\", \"simple\", \"give\", \"flexible\", \"solution\", \"improve\", \"choose\", \"manage\", \"transcription\", \"seamlessly\", \"dictation\", \"document\", \"management\", \"system\", \"olympus\", \"power\", \"productivity\", \"reliable\", \"secure\", \"thank\", \"file\", \"engine\", \"software\", \"creation\", \"email\", \"old\", \"assistant\", \"side\", \"daily\", \"use\", \"send\", \"automatically\", \"transcribe\", \"background\", \"speech\", \"example\", \"work\", \"recognition\", \"support\", \"hope\", \"enjoy\", \"simple\", \"give\", \"flexible\", \"solution\", \"improve\", \"choose\", \"manage\", \"transcription\", \"seamlessly\", \"dictation\", \"document\", \"secure\", \"system\", \"management\", \"olympus\", \"power\", \"productivity\", \"reliable\", \"thank\"], \"Freq\": [12.0, 7.0, 7.0, 5.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 12.675135289896318, 7.844062177021351, 7.842505260349943, 5.8964442915109885, 4.937202852726857, 3.9715671231291934, 3.971392347605101, 3.970739756416378, 3.970469321860581, 3.969773336474518, 3.9683945517844563, 3.967149545890614, 3.9669354518672746, 3.966237308758692, 3.9661536370743184, 3.965039053519442, 3.9626461392451415, 3.9607121006266883, 3.0006665505835644, 2.999301431469461, 2.997844968768692, 2.034825837346533, 2.0336553927530923, 2.0331936401338853, 2.03240750989589, 2.032385692923747, 2.0321696809248344, 2.0318134169621445, 2.0298930439196488, 2.0275682177781906, 0.0009162757967449835, 0.0009101491103331884, 0.0009070345597089156, 0.0009059197623710204, 0.000904228511580606, 0.0009031326580275432, 0.0008943043363014956, 0.0008921906983086446, 0.0008894181717995892, 0.0008862691375669886, 0.0009872978960609022, 0.0009637091839865015, 0.000957303742740863, 0.0009522264384099635, 0.0009422000702915811, 0.0009407151291578578, 0.0009400496547164577, 0.0009354349191316041, 0.0009213780387926352, 0.0010045399962214682, 0.0009830315485189832, 0.0009783438497628608, 0.0010783451299270913, 0.001067774053995616, 0.0010394722614533837, 0.001038592411446907, 0.0010324258394881405, 0.0010307997079580875, 0.0010249528863675284, 0.0010118163335752837, 0.0011676493135912148, 0.0013731855310672233, 0.001173512045001067, 0.001069147774392608, 0.0011193425142700967, 0.0010114497417391117, 0.0010013309486705114, 0.0009951914604041227, 0.000992047902109325, 0.000985807996983492, 0.0008429570907142127, 0.0008398302420313285, 0.0008393049797584277, 0.0008380483291778951, 0.0008394627364091223, 0.0008378455718387671, 0.0008351469288592388, 0.0008370842466324741, 0.0008357871717047047, 0.0008357224037647136, 0.0008481709416636382, 0.0008478109997164653, 0.0008465341369623142, 0.0008444175791588781, 0.0008466102821950024, 0.0008445439370241403, 0.0008446596167599437, 0.0008425877418434689, 0.0008422269100521744, 0.0008522341606035861, 0.0008506888827261945, 0.0008487760356663022, 0.0008721003755395801, 0.000863098712405831, 0.0008649548001228263, 0.0008637550360057794, 0.0008617684590043861, 0.0008605445419754682, 0.0008603229072289042, 0.0008607299473542256, 0.000923845637492398, 0.0008913903528465666, 0.0008747517932203711, 0.0008581770481297507, 0.0008642611030697722, 0.0008570067124290099, 0.0008553564329452736, 0.0008539912213819101, 0.0008502020744314042, 0.0008469634231906748, 0.0008416043294165022, 0.0008424668614740104, 0.0008404926637901181, 0.0008402455634459818, 0.0008397812892843456, 0.0008403614572561398, 0.000839770297163097, 0.0008409912486192354, 0.000840621455869718, 0.000840287816397602, 0.0008507004050570786, 0.0008483015175556993, 0.0008471252335055593, 0.0008459570823543778, 0.0008466021864412935, 0.0008464587170206046, 0.0008469923749764802, 0.0008440469947880564, 0.0008446490834640747, 0.0008583321776554941, 0.00084960252723596, 0.0008483652464436316, 0.0008642080065381602, 0.0008592335951361474, 0.0008571061431375067, 0.0008577764719188483, 0.0008558233054033563, 0.0008572944705790135, 0.0008564373392747198, 0.0008559788470959368, 0.0008559798637083066, 0.0009121194226086168, 0.0008725464518101378, 0.0008777294593627803, 0.0008697817744704472, 0.0008607717296516657, 0.0008544124380488833, 0.0008542575317390339, 0.0008533504593520734, 0.0008532881283061497, 0.0008421785049026907, 0.0008420858110612669, 0.0008413718334122465, 0.0008422319992237865, 0.0008408860643159295, 0.0008403596344529839, 0.0008422338416647744, 0.0008409724049125676, 0.0008415210075998154, 0.000839902772620442, 0.0008474541123078656, 0.0008480464888516871, 0.0008475404529045036, 0.0008444474392130186, 0.0008472111006948114, 0.0008467014433981001, 0.0008459247592230445, 0.0008450773634335238, 0.000843491339405214, 0.0008553740672577572, 0.0008543327069049281, 0.0008528642814376022, 0.0008642005031736769, 0.0008594602201741476, 0.0008590416684076637, 0.000857773052488849, 0.0008577756573192112, 0.000857382137337183, 0.0008582179702211937, 0.0008570733696405965, 0.000902844368712674, 0.00088362459611933, 0.0008680065415274644, 0.00086010030958631, 0.0008557625681764046, 0.0008572266099048284, 0.0008549542448423161, 0.0008544970018150871, 0.0008543228593755102, 0.000854250368852505, 0.000849054946768957, 0.0008490997893901555, 0.0008487569050758711, 0.0008489431256357563, 0.0008488756397107843, 0.0008491127918475044, 0.0008488020648301757, 0.0008488893398609665, 0.0008489660860726358, 0.000848733500652643, 0.0008493572380456644, 0.0008501460115070852, 0.0008507490718215906, 0.0008501687182374798, 0.0008501312331043422, 0.0008496609247080384, 0.0008496786841619784, 0.0008499006139096071, 0.0008497471849128898, 0.0008525276811336814, 0.000852130313351774, 0.0008510763531870563, 0.000852165515126548, 0.0008525367511405151, 0.0008524951432769985, 0.0008528684723694658, 0.0008534255483835908, 0.0008513114756718976, 0.0008527297583488702, 0.000851834618443673, 0.0008522967448058403, 0.0008520365688056193, 0.0008557068770954262, 0.0008611913136052041, 0.000856049253996741, 0.0008551847491495902, 0.0008517106828258203, 0.0008515464713034966, 0.0008511975614601967, 0.0008511150434259969, 0.000849209346655214, 0.0008493350749676652, 0.0008487562682281966, 0.0008488944869478857, 0.0008490496976936649, 0.0008488655117392168, 0.0008489313875418577, 0.0008491674372177304, 0.000848860185880293, 0.0008487385153651173, 0.0008501415621761262, 0.0008501813159088073, 0.0008505552038858746, 0.0008498843992738056, 0.0008497253843430808, 0.0008502137782870095, 0.0008495342240495658, 0.0008498811657166018, 0.0008499212998677775, 0.0008514552740439966, 0.0008505785362202074, 0.0008508689857408017, 0.0008518477391242145, 0.0008521290586009395, 0.0008530141656316089, 0.0008529044148959293, 0.0008521807955161993, 0.0008518320151597728, 0.0008512876996971441, 0.0008520420061687683, 0.0008518145793121057, 0.0008606875236822371, 0.0008538836121009192, 0.0008533015084011644, 0.0008529127841028095, 0.0008528358761638265, 0.0008513412118987118, 0.0008510644574439216, 0.0008508686687253896, 0.0008505719422996351, 0.0006388746522746462, 0.0006388746522746462, 0.0006388746522746462, 0.0006388746522746462, 0.0006388746522746462, 0.0006388746522746462, 0.0006388746522746462, 0.0006388746522746462, 0.0006388746522746462, 0.0006388746522746462, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746522746462, 0.0006388746522746462, 0.0006388746998745163, 0.0006388746522746462, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388748426741269, 0.0006388747474743864, 0.0006388747474743864, 0.0006388747474743864, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388746998745163, 0.0006388745114848642, 0.0006388745114848642, 0.0006388745114848642, 0.0006388745114848642, 0.0006388745114848642, 0.0006388745114848642, 0.0006388745114848642, 0.0006388745114848642, 0.0006388745114848642, 0.0006388745114848642, 0.0006388745114848642, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745114848642, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388746542844432, 0.0006388746066845835, 0.0006388746066845835, 0.0006388746066845835, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388745590847238, 0.0006388733851666088, 0.0006388733851666088, 0.0006388733851666088, 0.0006388733851666088, 0.0006388733851666088, 0.0006388733851666088, 0.0006388733851666088, 0.0006388733851666088, 0.0006388733851666088, 0.0006388733851666088, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388733851666088, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.000638873527965936, 0.0006388734803661602, 0.0006388734803661602, 0.0006388734803661602, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844, 0.0006388734327663844], \"Total\": [12.0, 7.0, 7.0, 5.0, 4.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 3.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 2.0, 12.682885786718408, 7.851458907356189, 7.849917286101086, 5.903835062012767, 4.944461447073893, 3.978749068800432, 3.978575562194032, 3.977928882380741, 3.9776613629615034, 3.976971352409388, 3.9756040170119817, 3.9743706667417724, 3.974158525092121, 3.9734665669134484, 3.973383069188902, 3.9722785553477675, 3.969907148911797, 3.9679900842794797, 3.0078192527103904, 3.006465970350618, 3.005022718459999, 2.0419043203196985, 2.04074442335768, 2.0402868549666247, 2.039507382850582, 2.039485769410248, 2.0392720102073, 2.0389189709918103, 2.037015285259103, 2.034711202542028, 1.0712994679177699, 1.0714470920393193, 1.0717373221947337, 1.0717238479900926, 1.0725305277314314, 1.07232416993523, 1.07350793565498, 1.0738637899474337, 1.072918854916694, 1.0738854490117293, 2.034711202542028, 2.037015285259103, 2.0389189709918103, 2.0392720102073, 2.0402868549666247, 2.039485769410248, 2.039507382850582, 2.04074442335768, 2.0419043203196985, 3.005022718459999, 3.006465970350618, 3.0078192527103904, 3.9679900842794797, 3.969907148911797, 3.9734665669134484, 3.9722785553477675, 3.974158525092121, 3.9743706667417724, 3.973383069188902, 3.976971352409388, 5.903835062012767, 12.682885786718408, 7.849917286101086, 4.944461447073893, 7.851458907356189, 3.9776613629615034, 3.9756040170119817, 3.977928882380741, 3.978749068800432, 3.978575562194032, 1.072918854916694, 1.0717373221947337, 1.0717238479900926, 1.0714470920393193, 1.0738854490117293, 1.07232416993523, 1.0712994679177699, 1.0738637899474337, 1.0725305277314314, 1.07350793565498, 2.037015285259103, 2.039507382850582, 2.039485769410248, 2.034711202542028, 2.0419043203196985, 2.0389189709918103, 2.04074442335768, 2.0392720102073, 2.0402868549666247, 3.005022718459999, 3.006465970350618, 3.0078192527103904, 3.973383069188902, 3.969907148911797, 3.978575562194032, 3.9756040170119817, 3.9722785553477675, 3.9679900842794797, 3.9734665669134484, 3.977928882380741, 12.682885786718408, 7.851458907356189, 7.849917286101086, 3.9743706667417724, 5.903835062012767, 3.978749068800432, 3.974158525092121, 3.976971352409388, 4.944461447073893, 3.9776613629615034, 1.0717238479900926, 1.072918854916694, 1.0712994679177699, 1.0714470920393193, 1.0717373221947337, 1.0725305277314314, 1.07232416993523, 1.0738854490117293, 1.07350793565498, 1.0738637899474337, 2.034711202542028, 2.039485769410248, 2.039507382850582, 2.037015285259103, 2.0392720102073, 2.0402868549666247, 2.0419043203196985, 2.0389189709918103, 2.04074442335768, 3.006465970350618, 3.0078192527103904, 3.005022718459999, 3.9756040170119817, 3.9722785553477675, 3.973383069188902, 3.977928882380741, 3.969907148911797, 3.976971352409388, 3.974158525092121, 3.9743706667417724, 3.9776613629615034, 12.682885786718408, 5.903835062012767, 7.851458907356189, 7.849917286101086, 4.944461447073893, 3.978749068800432, 3.9679900842794797, 3.9734665669134484, 3.978575562194032, 1.0714470920393193, 1.07232416993523, 1.0717238479900926, 1.072918854916694, 1.0717373221947337, 1.0712994679177699, 1.0738854490117293, 1.0725305277314314, 1.07350793565498, 1.0738637899474337, 2.037015285259103, 2.039485769410248, 2.039507382850582, 2.034711202542028, 2.0419043203196985, 2.04074442335768, 2.0402868549666247, 2.0392720102073, 2.0389189709918103, 3.0078192527103904, 3.005022718459999, 3.006465970350618, 3.9679900842794797, 3.9722785553477675, 3.9776613629615034, 3.9743706667417724, 3.9756040170119817, 3.974158525092121, 3.978749068800432, 3.978575562194032, 12.682885786718408, 7.851458907356189, 7.849917286101086, 5.903835062012767, 3.9734665669134484, 4.944461447073893, 3.977928882380741, 3.976971352409388, 3.973383069188902, 3.969907148911797, 1.0712994679177699, 1.0717373221947337, 1.0714470920393193, 1.0717238479900926, 1.07232416993523, 1.072918854916694, 1.0725305277314314, 1.07350793565498, 1.0738854490117293, 1.0738637899474337, 2.034711202542028, 2.037015285259103, 2.04074442335768, 2.039507382850582, 2.039485769410248, 2.0389189709918103, 2.0392720102073, 2.0402868549666247, 2.0419043203196985, 3.0078192527103904, 3.006465970350618, 3.005022718459999, 3.9679900842794797, 3.9722785553477675, 3.973383069188902, 3.9756040170119817, 3.978575562194032, 3.969907148911797, 3.976971352409388, 3.974158525092121, 3.978749068800432, 3.977928882380741, 5.903835062012767, 12.682885786718408, 7.849917286101086, 7.851458907356189, 4.944461447073893, 3.9734665669134484, 3.9743706667417724, 3.9776613629615034, 1.0714470920393193, 1.0717373221947337, 1.0712994679177699, 1.0717238479900926, 1.07232416993523, 1.0725305277314314, 1.072918854916694, 1.07350793565498, 1.0738637899474337, 1.0738854490117293, 2.034711202542028, 2.037015285259103, 2.039507382850582, 2.0389189709918103, 2.039485769410248, 2.04074442335768, 2.0392720102073, 2.0402868549666247, 2.0419043203196985, 3.0078192527103904, 3.005022718459999, 3.006465970350618, 3.9679900842794797, 3.969907148911797, 3.974158525092121, 3.9756040170119817, 3.9734665669134484, 3.973383069188902, 3.9722785553477675, 3.978575562194032, 3.977928882380741, 12.682885786718408, 5.903835062012767, 7.849917286101086, 4.944461447073893, 7.851458907356189, 3.978749068800432, 3.976971352409388, 3.9776613629615034, 3.9743706667417724, 1.0712994679177699, 1.0714470920393193, 1.0717238479900926, 1.0717373221947337, 1.07232416993523, 1.0725305277314314, 1.072918854916694, 1.07350793565498, 1.0738637899474337, 1.0738854490117293, 2.034711202542028, 2.037015285259103, 2.0389189709918103, 2.0392720102073, 2.039485769410248, 2.039507382850582, 2.0402868549666247, 2.04074442335768, 2.0419043203196985, 3.005022718459999, 3.006465970350618, 3.0078192527103904, 3.9679900842794797, 3.969907148911797, 3.9722785553477675, 3.973383069188902, 3.9734665669134484, 3.974158525092121, 3.9743706667417724, 3.9756040170119817, 12.682885786718408, 5.903835062012767, 7.851458907356189, 7.849917286101086, 4.944461447073893, 3.977928882380741, 3.978749068800432, 3.976971352409388, 3.978575562194032, 3.9776613629615034, 1.0712994679177699, 1.0714470920393193, 1.0717238479900926, 1.0717373221947337, 1.07232416993523, 1.0725305277314314, 1.072918854916694, 1.07350793565498, 1.0738637899474337, 1.0738854490117293, 2.034711202542028, 2.037015285259103, 2.0389189709918103, 2.0392720102073, 2.039485769410248, 2.039507382850582, 2.0402868549666247, 2.04074442335768, 2.0419043203196985, 3.005022718459999, 3.006465970350618, 3.0078192527103904, 3.9679900842794797, 3.969907148911797, 3.9722785553477675, 3.973383069188902, 3.9734665669134484, 3.974158525092121, 3.9743706667417724, 3.9756040170119817, 12.682885786718408, 5.903835062012767, 7.851458907356189, 7.849917286101086, 4.944461447073893, 3.977928882380741, 3.978749068800432, 3.976971352409388, 3.978575562194032, 3.9776613629615034, 1.0712994679177699, 1.0714470920393193, 1.0717238479900926, 1.0717373221947337, 1.07232416993523, 1.0725305277314314, 1.072918854916694, 1.07350793565498, 1.0738637899474337, 1.0738854490117293, 2.034711202542028, 2.037015285259103, 2.0389189709918103, 2.0392720102073, 2.039485769410248, 2.039507382850582, 2.0402868549666247, 2.04074442335768, 2.0419043203196985, 3.005022718459999, 3.006465970350618, 3.0078192527103904, 3.9679900842794797, 3.969907148911797, 3.9722785553477675, 3.973383069188902, 3.9734665669134484, 3.974158525092121, 3.9743706667417724, 3.9756040170119817, 12.682885786718408, 5.903835062012767, 3.978575562194032, 7.849917286101086, 7.851458907356189, 4.944461447073893, 3.977928882380741, 3.978749068800432, 3.976971352409388, 3.9776613629615034], \"Category\": [\"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Default\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic1\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic2\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic3\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic4\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic5\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic6\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic7\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic8\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic9\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\", \"Topic10\"], \"logprob\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, -2.3179, -2.7978, -2.798, -3.0832, -3.2608, -3.4784, -3.4785, -3.4786, -3.4787, -3.4789, -3.4792, -3.4795, -3.4796, -3.4798, -3.4798, -3.4801, -3.4807, -3.4812, -3.7588, -3.7592, -3.7597, -4.1472, -4.1478, -4.148, -4.1484, -4.1484, -4.1485, -4.1487, -4.1496, -4.1507, -3.7695, -3.7762, -3.7796, -3.7809, -3.7827, -3.7839, -3.7938, -3.7961, -3.7992, -3.8028, -3.6948, -3.719, -3.7257, -3.731, -3.7416, -3.7432, -3.7439, -3.7488, -3.7639, -3.6775, -3.6992, -3.704, -3.6066, -3.6165, -3.6433, -3.6442, -3.6501, -3.6517, -3.6574, -3.6703, -3.5271, -3.3649, -3.5221, -3.6152, -3.5693, -3.6707, -3.6807, -3.6869, -3.69, -3.6963, -3.7008, -3.7045, -3.7052, -3.7067, -3.705, -3.7069, -3.7101, -3.7078, -3.7094, -3.7095, -3.6947, -3.6951, -3.6966, -3.6991, -3.6965, -3.6989, -3.6988, -3.7013, -3.7017, -3.6899, -3.6917, -3.694, -3.6668, -3.6772, -3.6751, -3.6765, -3.6788, -3.6802, -3.6804, -3.68, -3.6092, -3.645, -3.6638, -3.6829, -3.6759, -3.6843, -3.6862, -3.6878, -3.6923, -3.6961, -3.7021, -3.7011, -3.7034, -3.7037, -3.7043, -3.7036, -3.7043, -3.7028, -3.7033, -3.7037, -3.6913, -3.6942, -3.6956, -3.6969, -3.6962, -3.6963, -3.6957, -3.6992, -3.6985, -3.6824, -3.6926, -3.6941, -3.6756, -3.6814, -3.6838, -3.6831, -3.6853, -3.6836, -3.6846, -3.6852, -3.6852, -3.6216, -3.666, -3.6601, -3.6692, -3.6796, -3.687, -3.6872, -3.6882, -3.6883, -3.7013, -3.7014, -3.7023, -3.7013, -3.7029, -3.7035, -3.7013, -3.7027, -3.7021, -3.704, -3.6951, -3.6944, -3.695, -3.6986, -3.6954, -3.696, -3.6969, -3.6979, -3.6998, -3.6858, -3.687, -3.6887, -3.6755, -3.681, -3.6815, -3.683, -3.683, -3.6834, -3.6825, -3.6838, -3.6318, -3.6533, -3.6711, -3.6803, -3.6853, -3.6836, -3.6863, -3.6868, -3.687, -3.6871, -3.6915, -3.6915, -3.6919, -3.6916, -3.6917, -3.6914, -3.6918, -3.6917, -3.6916, -3.6919, -3.6912, -3.6902, -3.6895, -3.6902, -3.6903, -3.6908, -3.6908, -3.6905, -3.6907, -3.6874, -3.6879, -3.6891, -3.6879, -3.6874, -3.6875, -3.687, -3.6864, -3.6889, -3.6872, -3.6882, -3.6877, -3.688, -3.6837, -3.6773, -3.6833, -3.6843, -3.6884, -3.6886, -3.689, -3.6891, -3.691, -3.6908, -3.6915, -3.6913, -3.6912, -3.6914, -3.6913, -3.691, -3.6914, -3.6915, -3.6899, -3.6898, -3.6894, -3.6902, -3.6904, -3.6898, -3.6906, -3.6902, -3.6901, -3.6883, -3.6894, -3.689, -3.6879, -3.6875, -3.6865, -3.6866, -3.6875, -3.6879, -3.6885, -3.6876, -3.6879, -3.6775, -3.6855, -3.6862, -3.6866, -3.6867, -3.6885, -3.6888, -3.689, -3.6894, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889, -3.6889], \"loglift\": [30.0, 29.0, 28.0, 27.0, 26.0, 25.0, 24.0, 23.0, 22.0, 21.0, 20.0, 19.0, 18.0, 17.0, 16.0, 15.0, 14.0, 13.0, 12.0, 11.0, 10.0, 9.0, 8.0, 7.0, 6.0, 5.0, 4.0, 3.0, 2.0, 1.0, 0.0016, 0.0013, 0.0013, 0.001, 0.0008, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, 0.0004, -0.0002, -0.0002, -0.0002, -0.0012, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, -0.0013, 1.0214, 1.0146, 1.0109, 1.0097, 1.0071, 1.006, 0.9951, 0.9924, 0.9902, 0.9857, 0.4546, 0.4293, 0.4217, 0.4162, 0.4051, 0.4039, 0.4032, 0.3977, 0.382, 0.082, 0.0599, 0.0546, -0.1251, -0.1354, -0.1632, -0.1637, -0.1701, -0.1718, -0.1772, -0.191, -0.4429, -1.0454, -0.7227, -0.3536, -0.7702, -0.1916, -0.2011, -0.2078, -0.2112, -0.2175, 1.0886, 1.086, 1.0854, 1.0841, 1.0835, 1.0831, 1.0808, 1.0807, 1.0804, 1.0794, 0.4537, 0.452, 0.4505, 0.4504, 0.4494, 0.4484, 0.4477, 0.446, 0.445, 0.0696, 0.0673, 0.0646, -0.1866, -0.1961, -0.1962, -0.1968, -0.1983, -0.1986, -0.2003, -0.2009, -1.2896, -0.8459, -0.8645, -0.203, -0.5917, -0.2055, -0.2062, -0.2085, -0.4307, -0.217, 1.0885, 1.0884, 1.0875, 1.0871, 1.0863, 1.0862, 1.0857, 1.0857, 1.0856, 1.0849, 0.4581, 0.453, 0.4516, 0.4514, 0.4511, 0.4504, 0.4502, 0.4482, 0.448, 0.0766, 0.066, 0.0654, -0.196, -0.2009, -0.2036, -0.204, -0.2043, -0.2043, -0.2046, -0.2052, -0.206, -1.3021, -0.5818, -0.8609, -0.8698, -0.418, -0.2081, -0.2056, -0.2081, -0.2094, 1.0895, 1.0886, 1.0883, 1.0882, 1.0877, 1.0875, 1.0873, 1.087, 1.0868, 1.0845, 0.4533, 0.4527, 0.4521, 0.4508, 0.4506, 0.4505, 0.4498, 0.4493, 0.4476, 0.0728, 0.0725, 0.0703, -0.194, -0.2005, -0.2024, -0.203, -0.2033, -0.2034, -0.2036, -0.2049, -1.3122, -0.8542, -0.8718, -0.596, -0.2051, -0.4221, -0.2072, -0.2075, -0.2068, -0.206, 1.0994, 1.0991, 1.0989, 1.0989, 1.0983, 1.098, 1.098, 1.0972, 1.0969, 1.0967, 0.4583, 0.4581, 0.457, 0.4569, 0.4569, 0.4566, 0.4564, 0.4562, 0.4552, 0.0712, 0.0711, 0.0704, -0.2063, -0.207, -0.2073, -0.2074, -0.2075, -0.2078, -0.2079, -0.2082, -0.2089, -0.209, -0.5995, -1.3578, -0.884, -0.8852, -0.4269, -0.2084, -0.2091, -0.21, 1.0998, 1.0997, 1.0994, 1.0992, 1.0988, 1.0984, 1.0981, 1.0979, 1.0972, 1.097, 0.4596, 0.4585, 0.4577, 0.4572, 0.4568, 0.4567, 0.4566, 0.4565, 0.4558, 0.0703, 0.0702, 0.07, -0.2063, -0.2065, -0.2065, -0.207, -0.2073, -0.2077, -0.208, -0.2087, -0.2089, -1.358, -0.6013, -0.8868, -0.4251, -0.8876, -0.2096, -0.2095, -0.2099, -0.2094, 1.1021, 1.1019, 1.1017, 1.1017, 1.1011, 1.1009, 1.1006, 1.1, 1.0997, 1.0996, 0.4606, 0.4594, 0.4585, 0.4583, 0.4582, 0.4582, 0.4578, 0.4576, 0.4571, 0.0706, 0.0702, 0.0697, -0.2073, -0.2078, -0.2084, -0.2087, -0.2087, -0.2089, -0.2089, -0.2092, -1.3693, -0.6047, -0.8898, -0.8896, -0.4273, -0.2098, -0.21, -0.2096, -0.21, -0.2098, 1.1021, 1.1019, 1.1017, 1.1017, 1.1011, 1.1009, 1.1006, 1.1, 1.0997, 1.0996, 0.4606, 0.4594, 0.4585, 0.4583, 0.4582, 0.4582, 0.4578, 0.4576, 0.4571, 0.0706, 0.0702, 0.0697, -0.2073, -0.2078, -0.2084, -0.2087, -0.2087, -0.2089, -0.2089, -0.2092, -1.3693, -0.6047, -0.8898, -0.8896, -0.4273, -0.2098, -0.21, -0.2096, -0.21, -0.2098, 1.1021, 1.1019, 1.1017, 1.1017, 1.1011, 1.1009, 1.1006, 1.1, 1.0997, 1.0996, 0.4606, 0.4594, 0.4585, 0.4583, 0.4582, 0.4582, 0.4578, 0.4576, 0.4571, 0.0706, 0.0702, 0.0697, -0.2073, -0.2078, -0.2084, -0.2087, -0.2087, -0.2089, -0.2089, -0.2092, -1.3693, -0.6047, -0.21, -0.8896, -0.8898, -0.4273, -0.2098, -0.21, -0.2096, -0.2098]}, \"token.table\": {\"Topic\": [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1], \"Freq\": [0.9320369340304345, 0.9818286659275635, 0.9807421422886554, 1.0066776535399824, 0.933064454592448, 0.9312167980344608, 1.0250033169591164, 1.016288554300236, 0.9325538191127424, 0.9333172001024037, 0.9978493119781217, 0.9806289581578453, 0.93344581038918, 1.0075802405344547, 1.008067035209422, 0.9983285589060129, 1.006698808130909, 1.0065023764766103, 1.0189189161398577, 0.9323743932167182, 1.0112324776966306, 1.0055483942201726, 1.005341108683181, 0.9800345291201911, 1.0057904987363462, 1.0061364217572035, 1.0053849518429538, 0.9829404770079103, 0.9315254846158818, 0.9974003581819804, 0.9330761855074857, 1.0069787262564736, 0.9806393503683696, 0.9794778237634868, 1.0191190185105068, 1.0056160228335438, 0.9809119579809106, 1.0064486519772045, 0.9311980164367397, 0.9802543182256185], \"Term\": [\"assistant\", \"automatically\", \"background\", \"choose\", \"creation\", \"daily\", \"dictation\", \"document\", \"email\", \"engine\", \"enjoy\", \"example\", \"file\", \"flexible\", \"give\", \"hope\", \"improve\", \"manage\", \"management\", \"old\", \"olympus\", \"power\", \"productivity\", \"recognition\", \"reliable\", \"seamlessly\", \"secure\", \"send\", \"side\", \"simple\", \"software\", \"solution\", \"speech\", \"support\", \"system\", \"thank\", \"transcribe\", \"transcription\", \"use\", \"work\"]}, \"R\": 30, \"lambda.step\": 0.01, \"plot.opts\": {\"xlab\": \"PC1\", \"ylab\": \"PC2\"}, \"topic.order\": [4, 1, 8, 2, 7, 9, 10, 3, 5, 6]};\n",
              "\n",
              "function LDAvis_load_lib(url, callback){\n",
              "  var s = document.createElement('script');\n",
              "  s.src = url;\n",
              "  s.async = true;\n",
              "  s.onreadystatechange = s.onload = callback;\n",
              "  s.onerror = function(){console.warn(\"failed to load library \" + url);};\n",
              "  document.getElementsByTagName(\"head\")[0].appendChild(s);\n",
              "}\n",
              "\n",
              "if(typeof(LDAvis) !== \"undefined\"){\n",
              "   // already loaded: just create the visualization\n",
              "   !function(LDAvis){\n",
              "       new LDAvis(\"#\" + \"ldavis_el1741399267795566886538442035\", ldavis_el1741399267795566886538442035_data);\n",
              "   }(LDAvis);\n",
              "}else if(typeof define === \"function\" && define.amd){\n",
              "   // require.js is available: use it to load d3/LDAvis\n",
              "   require.config({paths: {d3: \"https://d3js.org/d3.v5\"}});\n",
              "   require([\"d3\"], function(d3){\n",
              "      window.d3 = d3;\n",
              "      LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "        new LDAvis(\"#\" + \"ldavis_el1741399267795566886538442035\", ldavis_el1741399267795566886538442035_data);\n",
              "      });\n",
              "    });\n",
              "}else{\n",
              "    // require.js not available: dynamically load d3 & LDAvis\n",
              "    LDAvis_load_lib(\"https://d3js.org/d3.v5.js\", function(){\n",
              "         LDAvis_load_lib(\"https://cdn.jsdelivr.net/gh/bmabey/pyLDAvis@3.3.1/pyLDAvis/js/ldavis.v3.0.0.js\", function(){\n",
              "                 new LDAvis(\"#\" + \"ldavis_el1741399267795566886538442035\", ldavis_el1741399267795566886538442035_data);\n",
              "            })\n",
              "         });\n",
              "}\n",
              "</script>"
            ],
            "text/plain": [
              "PreparedData(topic_coordinates=              x         y  topics  cluster       Freq\n",
              "topic                                                \n",
              "3      0.019772  0.038625       1        1  99.777652\n",
              "0     -0.001336 -0.002754       2        1   0.030797\n",
              "7     -0.002208 -0.004292       3        1   0.026452\n",
              "1     -0.002240 -0.004345       4        1   0.026443\n",
              "6     -0.002239 -0.004372       5        1   0.026441\n",
              "8     -0.002329 -0.004546       6        1   0.026397\n",
              "9     -0.002345 -0.004548       7        1   0.026387\n",
              "2     -0.002360 -0.004588       8        1   0.019810\n",
              "4     -0.002364 -0.004586       9        1   0.019810\n",
              "5     -0.002350 -0.004593      10        1   0.019810, topic_info=            Term       Freq      Total Category  logprob  loglift\n",
              "6      dictation  12.000000  12.000000  Default  30.0000  30.0000\n",
              "34        system   7.000000   7.000000  Default  29.0000  29.0000\n",
              "18    management   7.000000   7.000000  Default  28.0000  28.0000\n",
              "7       document   5.000000   5.000000  Default  27.0000  27.0000\n",
              "20       olympus   4.000000   4.000000  Default  26.0000  26.0000\n",
              "..           ...        ...        ...      ...      ...      ...\n",
              "20       olympus   0.000639   4.944461  Topic10  -3.6889  -0.4273\n",
              "21         power   0.000639   3.977929  Topic10  -3.6889  -0.2098\n",
              "22  productivity   0.000639   3.978749  Topic10  -3.6889  -0.2100\n",
              "24      reliable   0.000639   3.976971  Topic10  -3.6889  -0.2096\n",
              "35         thank   0.000639   3.977661  Topic10  -3.6889  -0.2098\n",
              "\n",
              "[420 rows x 6 columns], token_table=      Topic      Freq           Term\n",
              "term                                \n",
              "0         1  0.932037      assistant\n",
              "1         1  0.981829  automatically\n",
              "2         1  0.980742     background\n",
              "3         1  1.006678         choose\n",
              "4         1  0.933064       creation\n",
              "5         1  0.931217          daily\n",
              "6         1  1.025003      dictation\n",
              "7         1  1.016289       document\n",
              "8         1  0.932554          email\n",
              "9         1  0.933317         engine\n",
              "10        1  0.997849          enjoy\n",
              "11        1  0.980629        example\n",
              "12        1  0.933446           file\n",
              "13        1  1.007580       flexible\n",
              "14        1  1.008067           give\n",
              "15        1  0.998329           hope\n",
              "16        1  1.006699        improve\n",
              "17        1  1.006502         manage\n",
              "18        1  1.018919     management\n",
              "19        1  0.932374            old\n",
              "20        1  1.011232        olympus\n",
              "21        1  1.005548          power\n",
              "22        1  1.005341   productivity\n",
              "23        1  0.980035    recognition\n",
              "24        1  1.005790       reliable\n",
              "25        1  1.006136     seamlessly\n",
              "26        1  1.005385         secure\n",
              "27        1  0.982940           send\n",
              "28        1  0.931525           side\n",
              "29        1  0.997400         simple\n",
              "30        1  0.933076       software\n",
              "31        1  1.006979       solution\n",
              "32        1  0.980639         speech\n",
              "33        1  0.979478        support\n",
              "34        1  1.019119         system\n",
              "35        1  1.005616          thank\n",
              "36        1  0.980912     transcribe\n",
              "37        1  1.006449  transcription\n",
              "38        1  0.931198            use\n",
              "39        1  0.980254           work, R=30, lambda_step=0.01, plot_opts={'xlab': 'PC1', 'ylab': 'PC2'}, topic_order=[4, 1, 8, 2, 7, 9, 10, 3, 5, 6])"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ydWIjtPLQhG7"
      },
      "source": [
        "# Library For Text Summarization\n",
        "from nltk.cluster.util import cosine_distance\n",
        "import networkx as nx"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CZ5qeu4bzt-i"
      },
      "source": [
        "def read_article(file_name):\n",
        "    file = open(file_name, \"r\")\n",
        "    filedata = file.readlines()\n",
        "    article = filedata[0].split(\". \")\n",
        "    sentences = []\n",
        "\n",
        "    for sentence in article:\n",
        "        print(sentence)\n",
        "        sentences.append(sentence.replace(\"[^a-zA-Z]\", \" \").split(\" \"))\n",
        "    sentences.pop() \n",
        "    \n",
        "    return sentences"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4myyEhwqzvGC"
      },
      "source": [
        "def sentence_similarity(sent1, sent2, stopwords=None):\n",
        "    if stopwords is None:\n",
        "        stopwords = []\n",
        " \n",
        "    sent1 = [w.lower() for w in sent1]\n",
        "    sent2 = [w.lower() for w in sent2]\n",
        " \n",
        "    all_words = list(set(sent1 + sent2))\n",
        " \n",
        "    vector1 = [0] * len(all_words)\n",
        "    vector2 = [0] * len(all_words)\n",
        " \n",
        "    # build the vector for the first sentence\n",
        "    for w in sent1:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector1[all_words.index(w)] += 1\n",
        " \n",
        "    # build the vector for the second sentence\n",
        "    for w in sent2:\n",
        "        if w in stopwords:\n",
        "            continue\n",
        "        vector2[all_words.index(w)] += 1\n",
        " \n",
        "    return 1 - cosine_distance(vector1, vector2)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-kolA-KIxWfM"
      },
      "source": [
        "def build_similarity_matrix(sentences, stop_words):\n",
        "    # Create an empty similarity matrix\n",
        "    similarity_matrix = np.zeros((len(sentences), len(sentences)))\n",
        " \n",
        "    for idx1 in range(len(sentences)):\n",
        "        for idx2 in range(len(sentences)):\n",
        "            if idx1 == idx2: #ignore if both are same sentences\n",
        "                continue \n",
        "            similarity_matrix[idx1][idx2] = sentence_similarity(sentences[idx1], sentences[idx2], stop_words)\n",
        "\n",
        "    return similarity_matrix"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oKA8L6UkxbDd"
      },
      "source": [
        "def generate_summary(file_name, top_n=5):\n",
        "    stop_words = stopwords.words('english')\n",
        "    summarize_text = []\n",
        "\n",
        "    # Step 1 - Read text anc split it\n",
        "    sentences =  read_article(file_name)\n",
        "\n",
        "    # Step 2 - Generate Similary Martix across sentences\n",
        "    sentence_similarity_martix = build_similarity_matrix(sentences, stop_words)\n",
        "\n",
        "    # Step 3 - Rank sentences in similarity martix\n",
        "    sentence_similarity_graph = nx.from_numpy_array(sentence_similarity_martix)\n",
        "    scores = nx.pagerank(sentence_similarity_graph)\n",
        "\n",
        "    # Step 4 - Sort the rank and pick top sentences\n",
        "    ranked_sentence = sorted(((scores[i],s) for i,s in enumerate(sentences)), reverse=True)    \n",
        "    print(\"Indexes of top ranked_sentence order are \", ranked_sentence)    \n",
        "\n",
        "    for i in range(top_n):\n",
        "      summarize_text.append(\" \".join(ranked_sentence[i][1]))\n",
        "\n",
        "    # Step 5 - Offcourse, output the summarize texr\n",
        "    print(\"Summarize Text: \\n\", \". \".join(summarize_text))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBq5-lIjxz9j",
        "outputId": "f55be281-868d-49ee-a6bf-ea3e67ae3cb0"
      },
      "source": [
        "generate_summary('/content/text_dummy.txt', 3)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "thank you for choosing the Olympus dictation management system\n",
            "the Olympus dictation management system gives you the power to manage your dictations transcriptions and document seamlessly and to improve the productivity of your daily work\n",
            "for example you can automatically send the dictation files are transcribed documents do your assistant off the old Side by email or FTP if you're using the speech recognition software, the speech recognition engine works in the background to support your document creation\n",
            "we hope you enjoy the simple flexible reliable and Secure Solutions from Olympus\n",
            "thank you for choosing the Olympus dictation management system the Olympus dictation management system gives you the power to manage your dictations transcriptions and document seamlessly and to improve the productivity for example you can automatically send transcribed in the background to support you and we hope you enjoy the simple flexible reliable and Secure Solutions from Olympus thank you for choosing the Olympus dictation management system the Olympus dictation management system gives you the power to manage your dictations transcriptions and document seamlessly and to improve the productivity and we hope you enjoy the simple flexible reliable and Secure Solutions from Olympus thank you for choosing the Olympus dictation management system the Olympus dictation management system gives you the power to manage your dictations transcriptions and document seamlessly and to improve the productivity of flexible reliable and Secure Solutions from Olympus\n",
            "Indexes of top ranked_sentence order are  [(0.37067728379026443, ['thank', 'you', 'for', 'choosing', 'the', 'Olympus', 'dictation', 'management', 'system']), (0.3529878418437946, ['the', 'Olympus', 'dictation', 'management', 'system', 'gives', 'you', 'the', 'power', 'to', 'manage', 'your', 'dictations', 'transcriptions', 'and', 'document', 'seamlessly', 'and', 'to', 'improve', 'the', 'productivity', 'of', 'your', 'daily', 'work']), (0.15307631129697669, ['we', 'hope', 'you', 'enjoy', 'the', 'simple', 'flexible', 'reliable', 'and', 'Secure', 'Solutions', 'from', 'Olympus']), (0.12325856306896422, ['for', 'example', 'you', 'can', 'automatically', 'send', 'the', 'dictation', 'files', 'are', 'transcribed', 'documents', 'do', 'your', 'assistant', 'off', 'the', 'old', 'Side', 'by', 'email', 'or', 'FTP', 'if', \"you're\", 'using', 'the', 'speech', 'recognition', 'software,', 'the', 'speech', 'recognition', 'engine', 'works', 'in', 'the', 'background', 'to', 'support', 'your', 'document', 'creation'])]\n",
            "Summarize Text: \n",
            " thank you for choosing the Olympus dictation management system. the Olympus dictation management system gives you the power to manage your dictations transcriptions and document seamlessly and to improve the productivity of your daily work. we hope you enjoy the simple flexible reliable and Secure Solutions from Olympus\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.7/dist-packages/networkx/algorithms/link_analysis/pagerank_alg.py:108: DeprecationWarning: networkx.pagerank_scipy is deprecated and will be removed in NetworkX 3.0, use networkx.pagerank instead.\n",
            "  G, alpha, personalization, max_iter, tol, nstart, weight, dangling\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "IW2WNN32yXHA"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}